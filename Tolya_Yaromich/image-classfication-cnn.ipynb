{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-20T22:36:05.598363Z","iopub.status.busy":"2024-02-20T22:36:05.597447Z","iopub.status.idle":"2024-02-20T22:36:05.606730Z","shell.execute_reply":"2024-02-20T22:36:05.605057Z","shell.execute_reply.started":"2024-02-20T22:36:05.598326Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import tensorflow as tf\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('./cards'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"markdown","metadata":{},"source":["Я нашел ограничитель так как у мен резко начал перегреваться комп от обучения модели,хотя я и все почистил и поменял термопасту я на всякий случай решил ограничить обучение"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import tensorflow as tf\n","\n","# Определяем процент использования ресурсов\n","limit = 0.7\n","\n","# Ограничиваем использование памяти GPU\n","gpus = tf.config.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","            tf.config.experimental.set_virtual_device_configuration(\n","                gpu,\n","                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=int(gpu.memory_limit * limit))]\n","            )\n","    except RuntimeError as e:\n","        print(e)\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["file_path_test =\"./cards.csv\"\n","data = pd.read_csv(file_path_test, encoding='cp1251', )"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class index</th>\n","      <th>filepaths</th>\n","      <th>labels</th>\n","      <th>card type</th>\n","      <th>data set</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/001.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/002.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/003.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/004.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/005.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class index                   filepaths        labels card type data set\n","0            0  train/ace of clubs/001.jpg  ace of clubs       ace    train\n","1            0  train/ace of clubs/002.jpg  ace of clubs       ace    train\n","2            0  train/ace of clubs/003.jpg  ace of clubs       ace    train\n","3            0  train/ace of clubs/004.jpg  ace of clubs       ace    train\n","4            0  train/ace of clubs/005.jpg  ace of clubs       ace    train"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Уникальные значения в столбце class index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n"," 48 49 50 51 52]\n","Уникальные значения в столбце filepaths: ['train/ace of clubs/001.jpg' 'train/ace of clubs/002.jpg'\n"," 'train/ace of clubs/003.jpg' ... 'valid/two of spades/3.jpg'\n"," 'valid/two of spades/4.jpg' 'valid/two of spades/5.jpg']\n","Уникальные значения в столбце labels: ['ace of clubs' 'ace of diamonds' 'ace of hearts' 'ace of spades'\n"," 'eight of clubs' 'eight of diamonds' 'eight of hearts' 'eight of spades'\n"," 'five of clubs' 'five of diamonds' 'five of hearts' 'five of spades'\n"," 'four of clubs' 'four of diamonds' 'four of hearts' 'four of spades'\n"," 'jack of clubs' 'jack of diamonds' 'jack of hearts' 'jack of spades'\n"," 'joker' 'king of clubs' 'king of diamonds' 'king of hearts'\n"," 'king of spades' 'nine of clubs' 'nine of diamonds' 'nine of hearts'\n"," 'nine of spades' 'queen of clubs' 'queen of diamonds' 'queen of hearts'\n"," 'queen of spades' 'seven of clubs' 'seven of diamonds' 'seven of hearts'\n"," 'seven of spades' 'six of clubs' 'six of diamonds' 'six of hearts'\n"," 'six of spades' 'ten of clubs' 'ten of diamonds' 'ten of hearts'\n"," 'ten of spades' 'three of clubs' 'three of diamonds' 'three of hearts'\n"," 'three of spades' 'two of clubs' 'two of diamonds' 'two of hearts'\n"," 'two of spades']\n","Уникальные значения в столбце card type: ['ace' 'eight' 'five' 'four' 'jack' 'xxx' 'king' 'nine' 'queen' 'seven'\n"," 'six' 'ten' 'three' 'two']\n","Уникальные значения в столбце data set: ['train' 'test' 'valid']\n"]}],"source":["for column in data.columns:\n","    unique_values = data[column].unique()\n","    print(f\"Уникальные значения в столбце {column}: {unique_values}\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Находим индексы строк, где значение в столбце 'data set' равно 'train'\n","train_indices = np.where(data['data set'] == 'train')[0]\n","\n","# Находим индексы строк, где значение в столбце 'data set' равно 'test'\n","test_indices = np.where(data['data set'] == 'test')[0]\n","\n","# Находим индексы строк, где значение в столбце 'data set' равно 'valid'\n","valid_indices = np.where(data['data set'] == 'valid')[0]\n","\n","# Используем найденные индексы для разделения датасета\n","train = data.iloc[train_indices]\n","test = data.iloc[test_indices]\n","valid = data.iloc[valid_indices]"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Уникальные значения в столбце class index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n"," 48 49 50 51 52]\n","Уникальные значения в столбце filepaths: ['train/ace of clubs/001.jpg' 'train/ace of clubs/002.jpg'\n"," 'train/ace of clubs/003.jpg' ... 'train/two of spades/153.jpg'\n"," 'train/two of spades/154.jpg' 'train/two of spades/155.jpg']\n","Уникальные значения в столбце labels: ['ace of clubs' 'ace of diamonds' 'ace of hearts' 'ace of spades'\n"," 'eight of clubs' 'eight of diamonds' 'eight of hearts' 'eight of spades'\n"," 'five of clubs' 'five of diamonds' 'five of hearts' 'five of spades'\n"," 'four of clubs' 'four of diamonds' 'four of hearts' 'four of spades'\n"," 'jack of clubs' 'jack of diamonds' 'jack of hearts' 'jack of spades'\n"," 'joker' 'king of clubs' 'king of diamonds' 'king of hearts'\n"," 'king of spades' 'nine of clubs' 'nine of diamonds' 'nine of hearts'\n"," 'nine of spades' 'queen of clubs' 'queen of diamonds' 'queen of hearts'\n"," 'queen of spades' 'seven of clubs' 'seven of diamonds' 'seven of hearts'\n"," 'seven of spades' 'six of clubs' 'six of diamonds' 'six of hearts'\n"," 'six of spades' 'ten of clubs' 'ten of diamonds' 'ten of hearts'\n"," 'ten of spades' 'three of clubs' 'three of diamonds' 'three of hearts'\n"," 'three of spades' 'two of clubs' 'two of diamonds' 'two of hearts'\n"," 'two of spades']\n","Уникальные значения в столбце card type: ['ace' 'eight' 'five' 'four' 'jack' 'xxx' 'king' 'nine' 'queen' 'seven'\n"," 'six' 'ten' 'three' 'two']\n","Уникальные значения в столбце data set: ['train']\n","--------------------------------------------------------------------\n","Уникальные значения в столбце class index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n"," 48 49 50 51 52]\n","Уникальные значения в столбце filepaths: ['test/ace of clubs/1.jpg' 'test/ace of clubs/2.jpg'\n"," 'test/ace of clubs/3.jpg' 'test/ace of clubs/4.jpg'\n"," 'test/ace of clubs/5.jpg' 'test/ace of diamonds/1.jpg'\n"," 'test/ace of diamonds/2.jpg' 'test/ace of diamonds/3.jpg'\n"," 'test/ace of diamonds/4.jpg' 'test/ace of diamonds/5.jpg'\n"," 'test/ace of hearts/1.jpg' 'test/ace of hearts/2.jpg'\n"," 'test/ace of hearts/3.jpg' 'test/ace of hearts/4.jpg'\n"," 'test/ace of hearts/5.jpg' 'test/ace of spades/1.jpg'\n"," 'test/ace of spades/2.jpg' 'test/ace of spades/3.jpg'\n"," 'test/ace of spades/4.jpg' 'test/ace of spades/5.jpg'\n"," 'test/eight of clubs/1.jpg' 'test/eight of clubs/2.jpg'\n"," 'test/eight of clubs/3.jpg' 'test/eight of clubs/4.jpg'\n"," 'test/eight of clubs/5.jpg' 'test/eight of diamonds/1.jpg'\n"," 'test/eight of diamonds/2.jpg' 'test/eight of diamonds/3.jpg'\n"," 'test/eight of diamonds/4.jpg' 'test/eight of diamonds/5.jpg'\n"," 'test/eight of hearts/1.jpg' 'test/eight of hearts/2.jpg'\n"," 'test/eight of hearts/3.jpg' 'test/eight of hearts/4.jpg'\n"," 'test/eight of hearts/5.jpg' 'test/eight of spades/1.jpg'\n"," 'test/eight of spades/2.jpg' 'test/eight of spades/3.jpg'\n"," 'test/eight of spades/4.jpg' 'test/eight of spades/5.jpg'\n"," 'test/five of clubs/1.jpg' 'test/five of clubs/2.jpg'\n"," 'test/five of clubs/3.jpg' 'test/five of clubs/4.jpg'\n"," 'test/five of clubs/5.jpg' 'test/five of diamonds/1.jpg'\n"," 'test/five of diamonds/2.jpg' 'test/five of diamonds/3.jpg'\n"," 'test/five of diamonds/4.jpg' 'test/five of diamonds/5.jpg'\n"," 'test/five of hearts/1.jpg' 'test/five of hearts/2.jpg'\n"," 'test/five of hearts/3.jpg' 'test/five of hearts/4.jpg'\n"," 'test/five of hearts/5.jpg' 'test/five of spades/1.jpg'\n"," 'test/five of spades/2.jpg' 'test/five of spades/3.jpg'\n"," 'test/five of spades/4.jpg' 'test/five of spades/5.jpg'\n"," 'test/four of clubs/1.jpg' 'test/four of clubs/2.jpg'\n"," 'test/four of clubs/3.jpg' 'test/four of clubs/4.jpg'\n"," 'test/four of clubs/5.jpg' 'test/four of diamonds/1.jpg'\n"," 'test/four of diamonds/2.jpg' 'test/four of diamonds/3.jpg'\n"," 'test/four of diamonds/4.jpg' 'test/four of diamonds/5.jpg'\n"," 'test/four of hearts/1.jpg' 'test/four of hearts/2.jpg'\n"," 'test/four of hearts/3.jpg' 'test/four of hearts/4.jpg'\n"," 'test/four of hearts/5.jpg' 'test/four of spades/1.jpg'\n"," 'test/four of spades/2.jpg' 'test/four of spades/3.jpg'\n"," 'test/four of spades/4.jpg' 'test/four of spades/5.jpg'\n"," 'test/jack of clubs/1.jpg' 'test/jack of clubs/2.jpg'\n"," 'test/jack of clubs/3.jpg' 'test/jack of clubs/4.jpg'\n"," 'test/jack of clubs/5.jpg' 'test/jack of diamonds/1.jpg'\n"," 'test/jack of diamonds/2.jpg' 'test/jack of diamonds/3.jpg'\n"," 'test/jack of diamonds/4.jpg' 'test/jack of diamonds/5.jpg'\n"," 'test/jack of hearts/1.jpg' 'test/jack of hearts/2.jpg'\n"," 'test/jack of hearts/3.jpg' 'test/jack of hearts/4.jpg'\n"," 'test/jack of hearts/5.jpg' 'test/jack of spades/1.jpg'\n"," 'test/jack of spades/2.jpg' 'test/jack of spades/3.jpg'\n"," 'test/jack of spades/4.jpg' 'test/jack of spades/5.jpg'\n"," 'test/joker/1.jpg' 'test/joker/2.jpg' 'test/joker/3.jpg'\n"," 'test/joker/4.jpg' 'test/joker/5.jpg' 'test/king of clubs/1.jpg'\n"," 'test/king of clubs/2.jpg' 'test/king of clubs/3.jpg'\n"," 'test/king of clubs/4.jpg' 'test/king of clubs/5.jpg'\n"," 'test/king of diamonds/1.jpg' 'test/king of diamonds/2.jpg'\n"," 'test/king of diamonds/3.jpg' 'test/king of diamonds/4.jpg'\n"," 'test/king of diamonds/5.jpg' 'test/king of hearts/1.jpg'\n"," 'test/king of hearts/2.jpg' 'test/king of hearts/3.jpg'\n"," 'test/king of hearts/4.jpg' 'test/king of hearts/5.jpg'\n"," 'test/king of spades/1.jpg' 'test/king of spades/2.jpg'\n"," 'test/king of spades/3.jpg' 'test/king of spades/4.jpg'\n"," 'test/king of spades/5.jpg' 'test/nine of clubs/1.jpg'\n"," 'test/nine of clubs/2.jpg' 'test/nine of clubs/3.jpg'\n"," 'test/nine of clubs/4.jpg' 'test/nine of clubs/5.jpg'\n"," 'test/nine of diamonds/1.jpg' 'test/nine of diamonds/2.jpg'\n"," 'test/nine of diamonds/3.jpg' 'test/nine of diamonds/4.jpg'\n"," 'test/nine of diamonds/5.jpg' 'test/nine of hearts/1.jpg'\n"," 'test/nine of hearts/2.jpg' 'test/nine of hearts/3.jpg'\n"," 'test/nine of hearts/4.jpg' 'test/nine of hearts/5.jpg'\n"," 'test/nine of spades/1.jpg' 'test/nine of spades/2.jpg'\n"," 'test/nine of spades/3.jpg' 'test/nine of spades/4.jpg'\n"," 'test/nine of spades/5.jpg' 'test/queen of clubs/1.jpg'\n"," 'test/queen of clubs/2.jpg' 'test/queen of clubs/3.jpg'\n"," 'test/queen of clubs/4.jpg' 'test/queen of clubs/5.jpg'\n"," 'test/queen of diamonds/1.jpg' 'test/queen of diamonds/2.jpg'\n"," 'test/queen of diamonds/3.jpg' 'test/queen of diamonds/4.jpg'\n"," 'test/queen of diamonds/5.jpg' 'test/queen of hearts/1.jpg'\n"," 'test/queen of hearts/2.jpg' 'test/queen of hearts/3.jpg'\n"," 'test/queen of hearts/4.jpg' 'test/queen of hearts/5.jpg'\n"," 'test/queen of spades/1.jpg' 'test/queen of spades/2.jpg'\n"," 'test/queen of spades/3.jpg' 'test/queen of spades/4.jpg'\n"," 'test/queen of spades/5.jpg' 'test/seven of clubs/1.jpg'\n"," 'test/seven of clubs/2.jpg' 'test/seven of clubs/3.jpg'\n"," 'test/seven of clubs/4.jpg' 'test/seven of clubs/5.jpg'\n"," 'test/seven of diamonds/1.jpg' 'test/seven of diamonds/2.jpg'\n"," 'test/seven of diamonds/3.jpg' 'test/seven of diamonds/4.jpg'\n"," 'test/seven of diamonds/5.jpg' 'test/seven of hearts/1.jpg'\n"," 'test/seven of hearts/2.jpg' 'test/seven of hearts/3.jpg'\n"," 'test/seven of hearts/4.jpg' 'test/seven of hearts/5.jpg'\n"," 'test/seven of spades/1.jpg' 'test/seven of spades/2.jpg'\n"," 'test/seven of spades/3.jpg' 'test/seven of spades/4.jpg'\n"," 'test/seven of spades/5.jpg' 'test/six of clubs/1.jpg'\n"," 'test/six of clubs/2.jpg' 'test/six of clubs/3.jpg'\n"," 'test/six of clubs/4.jpg' 'test/six of clubs/5.jpg'\n"," 'test/six of diamonds/1.jpg' 'test/six of diamonds/2.jpg'\n"," 'test/six of diamonds/3.jpg' 'test/six of diamonds/4.jpg'\n"," 'test/six of diamonds/5.jpg' 'test/six of hearts/1.jpg'\n"," 'test/six of hearts/2.jpg' 'test/six of hearts/3.jpg'\n"," 'test/six of hearts/4.jpg' 'test/six of hearts/5.jpg'\n"," 'test/six of spades/1.jpg' 'test/six of spades/2.jpg'\n"," 'test/six of spades/3.jpg' 'test/six of spades/4.jpg'\n"," 'test/six of spades/5.jpg' 'test/ten of clubs/1.jpg'\n"," 'test/ten of clubs/2.jpg' 'test/ten of clubs/3.jpg'\n"," 'test/ten of clubs/4.jpg' 'test/ten of clubs/5.jpg'\n"," 'test/ten of diamonds/1.jpg' 'test/ten of diamonds/2.jpg'\n"," 'test/ten of diamonds/3.jpg' 'test/ten of diamonds/4.jpg'\n"," 'test/ten of diamonds/5.jpg' 'test/ten of hearts/1.jpg'\n"," 'test/ten of hearts/2.jpg' 'test/ten of hearts/3.jpg'\n"," 'test/ten of hearts/4.jpg' 'test/ten of hearts/5.jpg'\n"," 'test/ten of spades/1.jpg' 'test/ten of spades/2.jpg'\n"," 'test/ten of spades/3.jpg' 'test/ten of spades/4.jpg'\n"," 'test/ten of spades/5.jpg' 'test/three of clubs/1.jpg'\n"," 'test/three of clubs/2.jpg' 'test/three of clubs/3.jpg'\n"," 'test/three of clubs/4.jpg' 'test/three of clubs/5.jpg'\n"," 'test/three of diamonds/1.jpg' 'test/three of diamonds/2.jpg'\n"," 'test/three of diamonds/3.jpg' 'test/three of diamonds/4.jpg'\n"," 'test/three of diamonds/5.jpg' 'test/three of hearts/1.jpg'\n"," 'test/three of hearts/2.jpg' 'test/three of hearts/3.jpg'\n"," 'test/three of hearts/4.jpg' 'test/three of hearts/5.jpg'\n"," 'test/three of spades/1.jpg' 'test/three of spades/2.jpg'\n"," 'test/three of spades/3.jpg' 'test/three of spades/4.jpg'\n"," 'test/three of spades/5.jpg' 'test/two of clubs/1.jpg'\n"," 'test/two of clubs/2.jpg' 'test/two of clubs/3.jpg'\n"," 'test/two of clubs/4.jpg' 'test/two of clubs/5.jpg'\n"," 'test/two of diamonds/1.jpg' 'test/two of diamonds/2.jpg'\n"," 'test/two of diamonds/3.jpg' 'test/two of diamonds/4.jpg'\n"," 'test/two of diamonds/5.jpg' 'test/two of hearts/1.jpg'\n"," 'test/two of hearts/2.jpg' 'test/two of hearts/3.jpg'\n"," 'test/two of hearts/4.jpg' 'test/two of hearts/5.jpg'\n"," 'test/two of spades/1.jpg' 'test/two of spades/2.jpg'\n"," 'test/two of spades/3.jpg' 'test/two of spades/4.jpg'\n"," 'test/two of spades/5.jpg']\n","Уникальные значения в столбце labels: ['ace of clubs' 'ace of diamonds' 'ace of hearts' 'ace of spades'\n"," 'eight of clubs' 'eight of diamonds' 'eight of hearts' 'eight of spades'\n"," 'five of clubs' 'five of diamonds' 'five of hearts' 'five of spades'\n"," 'four of clubs' 'four of diamonds' 'four of hearts' 'four of spades'\n"," 'jack of clubs' 'jack of diamonds' 'jack of hearts' 'jack of spades'\n"," 'joker' 'king of clubs' 'king of diamonds' 'king of hearts'\n"," 'king of spades' 'nine of clubs' 'nine of diamonds' 'nine of hearts'\n"," 'nine of spades' 'queen of clubs' 'queen of diamonds' 'queen of hearts'\n"," 'queen of spades' 'seven of clubs' 'seven of diamonds' 'seven of hearts'\n"," 'seven of spades' 'six of clubs' 'six of diamonds' 'six of hearts'\n"," 'six of spades' 'ten of clubs' 'ten of diamonds' 'ten of hearts'\n"," 'ten of spades' 'three of clubs' 'three of diamonds' 'three of hearts'\n"," 'three of spades' 'two of clubs' 'two of diamonds' 'two of hearts'\n"," 'two of spades']\n","Уникальные значения в столбце card type: ['ace' 'eight' 'five' 'four' 'jack' 'xxx' 'king' 'nine' 'queen' 'seven'\n"," 'six' 'ten' 'three' 'two']\n","Уникальные значения в столбце data set: ['test']\n","--------------------------------------------------------------------\n","Уникальные значения в столбце class index: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n"," 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n"," 48 49 50 51 52]\n","Уникальные значения в столбце filepaths: ['valid/ace of clubs/1.jpg' 'valid/ace of clubs/2.jpg'\n"," 'valid/ace of clubs/3.jpg' 'valid/ace of clubs/4.jpg'\n"," 'valid/ace of clubs/5.jpg' 'valid/ace of diamonds/1.jpg'\n"," 'valid/ace of diamonds/2.jpg' 'valid/ace of diamonds/3.jpg'\n"," 'valid/ace of diamonds/4.jpg' 'valid/ace of diamonds/5.jpg'\n"," 'valid/ace of hearts/1.jpg' 'valid/ace of hearts/2.jpg'\n"," 'valid/ace of hearts/3.jpg' 'valid/ace of hearts/4.jpg'\n"," 'valid/ace of hearts/5.jpg' 'valid/ace of spades/1.jpg'\n"," 'valid/ace of spades/2.jpg' 'valid/ace of spades/3.jpg'\n"," 'valid/ace of spades/4.jpg' 'valid/ace of spades/5.jpg'\n"," 'valid/eight of clubs/1.jpg' 'valid/eight of clubs/2.jpg'\n"," 'valid/eight of clubs/3.jpg' 'valid/eight of clubs/4.jpg'\n"," 'valid/eight of clubs/5.jpg' 'valid/eight of diamonds/1.jpg'\n"," 'valid/eight of diamonds/2.jpg' 'valid/eight of diamonds/3.jpg'\n"," 'valid/eight of diamonds/4.jpg' 'valid/eight of diamonds/5.jpg'\n"," 'valid/eight of hearts/1.jpg' 'valid/eight of hearts/2.jpg'\n"," 'valid/eight of hearts/3.jpg' 'valid/eight of hearts/4.jpg'\n"," 'valid/eight of hearts/5.jpg' 'valid/eight of spades/1.jpg'\n"," 'valid/eight of spades/2.jpg' 'valid/eight of spades/3.jpg'\n"," 'valid/eight of spades/4.jpg' 'valid/eight of spades/5.jpg'\n"," 'valid/five of clubs/1.jpg' 'valid/five of clubs/2.jpg'\n"," 'valid/five of clubs/3.jpg' 'valid/five of clubs/4.jpg'\n"," 'valid/five of clubs/5.jpg' 'valid/five of diamonds/1.jpg'\n"," 'valid/five of diamonds/2.jpg' 'valid/five of diamonds/3.jpg'\n"," 'valid/five of diamonds/4.jpg' 'valid/five of diamonds/5.jpg'\n"," 'valid/five of hearts/1.jpg' 'valid/five of hearts/2.jpg'\n"," 'valid/five of hearts/3.jpg' 'valid/five of hearts/4.jpg'\n"," 'valid/five of hearts/5.jpg' 'valid/five of spades/1.jpg'\n"," 'valid/five of spades/2.jpg' 'valid/five of spades/3.jpg'\n"," 'valid/five of spades/4.jpg' 'valid/five of spades/5.jpg'\n"," 'valid/four of clubs/1.jpg' 'valid/four of clubs/2.jpg'\n"," 'valid/four of clubs/3.jpg' 'valid/four of clubs/4.jpg'\n"," 'valid/four of clubs/5.jpg' 'valid/four of diamonds/1.jpg'\n"," 'valid/four of diamonds/2.jpg' 'valid/four of diamonds/3.jpg'\n"," 'valid/four of diamonds/4.jpg' 'valid/four of diamonds/5.jpg'\n"," 'valid/four of hearts/1.jpg' 'valid/four of hearts/2.jpg'\n"," 'valid/four of hearts/3.jpg' 'valid/four of hearts/4.jpg'\n"," 'valid/four of hearts/5.jpg' 'valid/four of spades/1.jpg'\n"," 'valid/four of spades/2.jpg' 'valid/four of spades/3.jpg'\n"," 'valid/four of spades/4.jpg' 'valid/four of spades/5.jpg'\n"," 'valid/jack of clubs/1.jpg' 'valid/jack of clubs/2.jpg'\n"," 'valid/jack of clubs/3.jpg' 'valid/jack of clubs/4.jpg'\n"," 'valid/jack of clubs/5.jpg' 'valid/jack of diamonds/1.jpg'\n"," 'valid/jack of diamonds/2.jpg' 'valid/jack of diamonds/3.jpg'\n"," 'valid/jack of diamonds/4.jpg' 'valid/jack of diamonds/5.jpg'\n"," 'valid/jack of hearts/1.jpg' 'valid/jack of hearts/2.jpg'\n"," 'valid/jack of hearts/3.jpg' 'valid/jack of hearts/4.jpg'\n"," 'valid/jack of hearts/5.jpg' 'valid/jack of spades/1.jpg'\n"," 'valid/jack of spades/2.jpg' 'valid/jack of spades/3.jpg'\n"," 'valid/jack of spades/4.jpg' 'valid/jack of spades/5.jpg'\n"," 'valid/joker/1.jpg' 'valid/joker/2.jpg' 'valid/joker/3.jpg'\n"," 'valid/joker/4.jpg' 'valid/joker/5.jpg' 'valid/king of clubs/1.jpg'\n"," 'valid/king of clubs/2.jpg' 'valid/king of clubs/3.jpg'\n"," 'valid/king of clubs/4.jpg' 'valid/king of clubs/5.jpg'\n"," 'valid/king of diamonds/1.jpg' 'valid/king of diamonds/2.jpg'\n"," 'valid/king of diamonds/3.jpg' 'valid/king of diamonds/4.jpg'\n"," 'valid/king of diamonds/5.jpg' 'valid/king of hearts/1.jpg'\n"," 'valid/king of hearts/2.jpg' 'valid/king of hearts/3.jpg'\n"," 'valid/king of hearts/4.jpg' 'valid/king of hearts/5.jpg'\n"," 'valid/king of spades/1.jpg' 'valid/king of spades/2.jpg'\n"," 'valid/king of spades/3.jpg' 'valid/king of spades/4.jpg'\n"," 'valid/king of spades/5.jpg' 'valid/nine of clubs/1.jpg'\n"," 'valid/nine of clubs/2.jpg' 'valid/nine of clubs/3.jpg'\n"," 'valid/nine of clubs/4.jpg' 'valid/nine of clubs/5.jpg'\n"," 'valid/nine of diamonds/1.jpg' 'valid/nine of diamonds/2.jpg'\n"," 'valid/nine of diamonds/3.jpg' 'valid/nine of diamonds/4.jpg'\n"," 'valid/nine of diamonds/5.jpg' 'valid/nine of hearts/1.jpg'\n"," 'valid/nine of hearts/2.jpg' 'valid/nine of hearts/3.jpg'\n"," 'valid/nine of hearts/4.jpg' 'valid/nine of hearts/5.jpg'\n"," 'valid/nine of spades/1.jpg' 'valid/nine of spades/2.jpg'\n"," 'valid/nine of spades/3.jpg' 'valid/nine of spades/4.jpg'\n"," 'valid/nine of spades/5.jpg' 'valid/queen of clubs/1.jpg'\n"," 'valid/queen of clubs/2.jpg' 'valid/queen of clubs/3.jpg'\n"," 'valid/queen of clubs/4.jpg' 'valid/queen of clubs/5.jpg'\n"," 'valid/queen of diamonds/1.jpg' 'valid/queen of diamonds/2.jpg'\n"," 'valid/queen of diamonds/3.jpg' 'valid/queen of diamonds/4.jpg'\n"," 'valid/queen of diamonds/5.jpg' 'valid/queen of hearts/1.jpg'\n"," 'valid/queen of hearts/2.jpg' 'valid/queen of hearts/3.jpg'\n"," 'valid/queen of hearts/4.jpg' 'valid/queen of hearts/5.jpg'\n"," 'valid/queen of spades/1.jpg' 'valid/queen of spades/2.jpg'\n"," 'valid/queen of spades/3.jpg' 'valid/queen of spades/4.jpg'\n"," 'valid/queen of spades/5.jpg' 'valid/seven of clubs/1.jpg'\n"," 'valid/seven of clubs/2.jpg' 'valid/seven of clubs/3.jpg'\n"," 'valid/seven of clubs/4.jpg' 'valid/seven of clubs/5.jpg'\n"," 'valid/seven of diamonds/1.jpg' 'valid/seven of diamonds/2.jpg'\n"," 'valid/seven of diamonds/3.jpg' 'valid/seven of diamonds/4.jpg'\n"," 'valid/seven of diamonds/5.jpg' 'valid/seven of hearts/1.jpg'\n"," 'valid/seven of hearts/2.jpg' 'valid/seven of hearts/3.jpg'\n"," 'valid/seven of hearts/4.jpg' 'valid/seven of hearts/5.jpg'\n"," 'valid/seven of spades/1.jpg' 'valid/seven of spades/2.jpg'\n"," 'valid/seven of spades/3.jpg' 'valid/seven of spades/4.jpg'\n"," 'valid/seven of spades/5.jpg' 'valid/six of clubs/1.jpg'\n"," 'valid/six of clubs/2.jpg' 'valid/six of clubs/3.jpg'\n"," 'valid/six of clubs/4.jpg' 'valid/six of clubs/5.jpg'\n"," 'valid/six of diamonds/1.jpg' 'valid/six of diamonds/2.jpg'\n"," 'valid/six of diamonds/3.jpg' 'valid/six of diamonds/4.jpg'\n"," 'valid/six of diamonds/5.jpg' 'valid/six of hearts/1.jpg'\n"," 'valid/six of hearts/2.jpg' 'valid/six of hearts/3.jpg'\n"," 'valid/six of hearts/4.jpg' 'valid/six of hearts/5.jpg'\n"," 'valid/six of spades/1.jpg' 'valid/six of spades/2.jpg'\n"," 'valid/six of spades/3.jpg' 'valid/six of spades/4.jpg'\n"," 'valid/six of spades/5.jpg' 'valid/ten of clubs/1.jpg'\n"," 'valid/ten of clubs/2.jpg' 'valid/ten of clubs/3.jpg'\n"," 'valid/ten of clubs/4.jpg' 'valid/ten of clubs/5.jpg'\n"," 'valid/ten of diamonds/1.jpg' 'valid/ten of diamonds/2.jpg'\n"," 'valid/ten of diamonds/3.jpg' 'valid/ten of diamonds/4.jpg'\n"," 'valid/ten of diamonds/5.jpg' 'valid/ten of hearts/1.jpg'\n"," 'valid/ten of hearts/2.jpg' 'valid/ten of hearts/3.jpg'\n"," 'valid/ten of hearts/4.jpg' 'valid/ten of hearts/5.jpg'\n"," 'valid/ten of spades/1.jpg' 'valid/ten of spades/2.jpg'\n"," 'valid/ten of spades/3.jpg' 'valid/ten of spades/4.jpg'\n"," 'valid/ten of spades/5.jpg' 'valid/three of clubs/1.jpg'\n"," 'valid/three of clubs/2.jpg' 'valid/three of clubs/3.jpg'\n"," 'valid/three of clubs/4.jpg' 'valid/three of clubs/5.jpg'\n"," 'valid/three of diamonds/1.jpg' 'valid/three of diamonds/2.jpg'\n"," 'valid/three of diamonds/3.jpg' 'valid/three of diamonds/4.jpg'\n"," 'valid/three of diamonds/5.jpg' 'valid/three of hearts/1.jpg'\n"," 'valid/three of hearts/2.jpg' 'valid/three of hearts/3.jpg'\n"," 'valid/three of hearts/4.jpg' 'valid/three of hearts/5.jpg'\n"," 'valid/three of spades/1.jpg' 'valid/three of spades/2.jpg'\n"," 'valid/three of spades/3.jpg' 'valid/three of spades/4.jpg'\n"," 'valid/three of spades/5.jpg' 'valid/two of clubs/1.jpg'\n"," 'valid/two of clubs/2.jpg' 'valid/two of clubs/3.jpg'\n"," 'valid/two of clubs/4.jpg' 'valid/two of clubs/5.jpg'\n"," 'valid/two of diamonds/1.jpg' 'valid/two of diamonds/2.jpg'\n"," 'valid/two of diamonds/3.jpg' 'valid/two of diamonds/4.jpg'\n"," 'valid/two of diamonds/5.jpg' 'valid/two of hearts/1.jpg'\n"," 'valid/two of hearts/2.jpg' 'valid/two of hearts/3.jpg'\n"," 'valid/two of hearts/4.jpg' 'valid/two of hearts/5.jpg'\n"," 'valid/two of spades/1.jpg' 'valid/two of spades/2.jpg'\n"," 'valid/two of spades/3.jpg' 'valid/two of spades/4.jpg'\n"," 'valid/two of spades/5.jpg']\n","Уникальные значения в столбце labels: ['ace of clubs' 'ace of diamonds' 'ace of hearts' 'ace of spades'\n"," 'eight of clubs' 'eight of diamonds' 'eight of hearts' 'eight of spades'\n"," 'five of clubs' 'five of diamonds' 'five of hearts' 'five of spades'\n"," 'four of clubs' 'four of diamonds' 'four of hearts' 'four of spades'\n"," 'jack of clubs' 'jack of diamonds' 'jack of hearts' 'jack of spades'\n"," 'joker' 'king of clubs' 'king of diamonds' 'king of hearts'\n"," 'king of spades' 'nine of clubs' 'nine of diamonds' 'nine of hearts'\n"," 'nine of spades' 'queen of clubs' 'queen of diamonds' 'queen of hearts'\n"," 'queen of spades' 'seven of clubs' 'seven of diamonds' 'seven of hearts'\n"," 'seven of spades' 'six of clubs' 'six of diamonds' 'six of hearts'\n"," 'six of spades' 'ten of clubs' 'ten of diamonds' 'ten of hearts'\n"," 'ten of spades' 'three of clubs' 'three of diamonds' 'three of hearts'\n"," 'three of spades' 'two of clubs' 'two of diamonds' 'two of hearts'\n"," 'two of spades']\n","Уникальные значения в столбце card type: ['ace' 'eight' 'five' 'four' 'jack' 'xxx' 'king' 'nine' 'queen' 'seven'\n"," 'six' 'ten' 'three' 'two']\n","Уникальные значения в столбце data set: ['valid']\n"]}],"source":["for column in train.columns:\n","    unique_values = train[column].unique()\n","    print(f\"Уникальные значения в столбце {column}: {unique_values}\")\n","print(\"--------------------------------------------------------------------\")\n","for column in test.columns:\n","    unique_values = test[column].unique()\n","    print(f\"Уникальные значения в столбце {column}: {unique_values}\")\n","print(\"--------------------------------------------------------------------\")\n","for column in valid.columns:\n","    unique_values = valid[column].unique()\n","    print(f\"Уникальные значения в столбце {column}: {unique_values}\")"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Размерность изображения: (224, 224)\n"]}],"source":["import cv2\n","\n","# Загрузка изображения\n","image = cv2.imread('./cards/train/ace of clubs/001.jpg')\n","\n","# Получение размерности изображения\n","image_shape = image.shape[:2]  # Получаем только ширину и высоту\n","\n","print(\"Размерность изображения:\", image_shape)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","image_folder = \"./cards\""]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["datagen = ImageDataGenerator(rescale=1./255)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 7624 validated image filenames belonging to 14 classes.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"filepaths\". These filename(s) will be ignored.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 2s/step - accuracy: 0.5559 - loss: 1.3787\n","Epoch 2/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 2s/step - accuracy: 0.8952 - loss: 0.3292\n","Epoch 3/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 2s/step - accuracy: 0.9380 - loss: 0.1956\n","Epoch 4/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 2s/step - accuracy: 0.9459 - loss: 0.1825\n","Epoch 5/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 2s/step - accuracy: 0.9544 - loss: 0.1390\n","Epoch 6/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 2s/step - accuracy: 0.9637 - loss: 0.1182\n","Epoch 7/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 2s/step - accuracy: 0.9626 - loss: 0.1240\n","Epoch 8/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 2s/step - accuracy: 0.9742 - loss: 0.0826\n","Epoch 9/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 2s/step - accuracy: 0.9690 - loss: 0.0960\n","Epoch 10/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 2s/step - accuracy: 0.9763 - loss: 0.0751\n"]},{"data":{"text/plain":["<keras.src.callbacks.history.History at 0x1fae70c7d30>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# Чтение изображений из папки с использованием путей из датасета\n","image_data_generator = datagen.flow_from_dataframe(\n","    dataframe=train,\n","    directory=image_folder,\n","    x_col='filepaths',  # Название столбца с путями к изображениям\n","    y_col='card type',       # Название столбца с метками\n","    target_size=(224, 224),  # Размер изображений\n","    batch_size=32,\n","    class_mode='categorical'  # Режим классификации\n",")\n","\n","# Создание модели нейронной сети\n","model = tf.keras.models.Sequential([\n","    tf.keras.applications.MobileNetV2(include_top=False, input_shape=(224, 224, 3)),\n","    tf.keras.layers.GlobalAveragePooling2D(),\n","    tf.keras.layers.Dense(256, activation='relu'),\n","    tf.keras.layers.Dense(14, activation='softmax')  # Пример: 10 классов для классификации\n","])\n","\n","# Компиляция модели\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Обучение модели\n","model.fit(image_data_generator, epochs=10)\"\"\""]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]},{"ename":"ValueError","evalue":"Unable to synchronously create dataset (name already exists)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_V2.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\group.py:183\u001b[0m, in \u001b[0;36mGroup.create_dataset\u001b[1;34m(self, name, shape, dtype, data, **kwds)\u001b[0m\n\u001b[0;32m    180\u001b[0m         parent_path, name \u001b[38;5;241m=\u001b[39m name\u001b[38;5;241m.\u001b[39mrsplit(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    181\u001b[0m         group \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequire_group(parent_path)\n\u001b[1;32m--> 183\u001b[0m dsid \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmake_new_dset(group, shape, dtype, data, name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    184\u001b[0m dset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mDataset(dsid)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dset\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\h5py\\_hl\\dataset.py:163\u001b[0m, in \u001b[0;36mmake_new_dset\u001b[1;34m(parent, shape, dtype, data, name, chunks, compression, shuffle, fletcher32, maxshape, compression_opts, fillvalue, scaleoffset, track_times, external, track_order, dcpl, dapl, efile_prefix, virtual_prefix, allow_unknown_filter, rdcc_nslots, rdcc_nbytes, rdcc_w0)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     sid \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(shape, maxshape)\n\u001b[1;32m--> 163\u001b[0m dset_id \u001b[38;5;241m=\u001b[39m \u001b[43mh5d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdcpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Empty)):\n\u001b[0;32m    166\u001b[0m     dset_id\u001b[38;5;241m.\u001b[39mwrite(h5s\u001b[38;5;241m.\u001b[39mALL, h5s\u001b[38;5;241m.\u001b[39mALL, data)\n","File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n","File \u001b[1;32mh5py\\h5d.pyx:137\u001b[0m, in \u001b[0;36mh5py.h5d.create\u001b[1;34m()\u001b[0m\n","\u001b[1;31mValueError\u001b[0m: Unable to synchronously create dataset (name already exists)"]}],"source":["model.save(\"model_V2.h5\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 265 validated image filenames belonging to 14 classes.\n","Found 265 validated image filenames belonging to 14 classes.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 335ms/step - accuracy: 0.5699 - loss: 3.0564\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 328ms/step - accuracy: 0.5581 - loss: 2.9119\n","Метрики на тестовом наборе данных: [3.1472280025482178, 0.5245283246040344]\n","Метрики на валидационном наборе данных: [3.112689256668091, 0.5132075548171997]\n"]}],"source":["test_datagen = ImageDataGenerator(rescale=1./255)\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","\n","test_generator = test_datagen.flow_from_dataframe(\n","    dataframe=test,\n","    directory=image_folder,\n","    x_col='filepaths',\n","    y_col='card type',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    shuffle=False  # Важно отключить перемешивание, чтобы сохранить соответствие между метками и предсказаниями\n",")\n","\n","valid_generator = valid_datagen.flow_from_dataframe(\n","    dataframe=valid,\n","    directory=image_folder,\n","    x_col='filepaths',\n","    y_col='card type',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='categorical',\n","    shuffle=False  # Важно отключить перемешивание, чтобы сохранить соответствие между метками и предсказаниями\n",")\n","\n","# Оценка модели на тестовом наборе данных\n","test_metrics = model.evaluate(test_generator)\n","\n","# Оценка модели на валидационном наборе данных\n","valid_metrics = model.evaluate(valid_generator)\n","\n","print(\"Метрики на тестовом наборе данных:\", test_metrics)\n","print(\"Метрики на валидационном наборе данных:\", valid_metrics)"]},{"cell_type":"markdown","metadata":{},"source":["------------------------------------------------------------V-3--------------------------------------------------------------------------------"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["import cv2\n","import pandas as pd\n","import numpy as np\n","\n","# Загрузка данных из CSV файла\n","data = pd.read_csv('./cards.csv')\n","\n","# Предварительная обработка данных\n","images = []\n","\n","for index, row in data.iterrows():\n","    # Загрузка изображения из файла\n","    image_path = row['filepaths']\n","    image = cv2.imread(image_path)\n","    \n","    # Масштабирование изображения до нужных размеров, если необходимо\n","    # image = cv2.resize(image, (desired_width, desired_height))\n","    \n","    # Преобразование изображения в матрицу\n","    image_matrix = np.array(image)\n","    \n","    # Добавление матрицы изображения в список\n","    images.append(image_matrix)\n","\n","# Добавление нового столбца 'image' в датафрейм с матрицами изображений\n","data['image'] = images\n","\n"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class index</th>\n","      <th>filepaths</th>\n","      <th>labels</th>\n","      <th>card type</th>\n","      <th>data set</th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/001.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/002.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[246, 248, 248], [249, 251, 251], [247, 249,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/003.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/004.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[255, 255, 252], [255, 255, 252], [252, 252,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/005.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[253, 255, 254], [250, 255, 253], [246, 254,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class index                   filepaths        labels card type data set  \\\n","0            0  train/ace of clubs/001.jpg  ace of clubs       ace    train   \n","1            0  train/ace of clubs/002.jpg  ace of clubs       ace    train   \n","2            0  train/ace of clubs/003.jpg  ace of clubs       ace    train   \n","3            0  train/ace of clubs/004.jpg  ace of clubs       ace    train   \n","4            0  train/ace of clubs/005.jpg  ace of clubs       ace    train   \n","\n","                                               image  \n","0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n","1  [[[246, 248, 248], [249, 251, 251], [247, 249,...  \n","2  [[[0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], ...  \n","3  [[[255, 255, 252], [255, 255, 252], [252, 252,...  \n","4  [[[253, 255, 254], [250, 255, 253], [246, 254,...  "]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Находим индексы строк, где значение в столбце 'data set' равно 'train'\n","train_indices = np.where(data['data set'] == 'train')[0]\n","\n","# Находим индексы строк, где значение в столбце 'data set' равно 'test'\n","test_indices = np.where(data['data set'] == 'test')[0]\n","\n","# Находим индексы строк, где значение в столбце 'data set' равно 'valid'\n","valid_indices = np.where(data['data set'] == 'valid')[0]\n","\n","# Используем найденные индексы для разделения датасета\n","train = data.iloc[train_indices]\n","test = data.iloc[test_indices]\n","valid = data.iloc[valid_indices]"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class index</th>\n","      <th>filepaths</th>\n","      <th>labels</th>\n","      <th>card type</th>\n","      <th>data set</th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/001.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/002.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[246, 248, 248], [249, 251, 251], [247, 249,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/003.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/004.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[255, 255, 252], [255, 255, 252], [252, 252,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/005.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[253, 255, 254], [250, 255, 253], [246, 254,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class index                   filepaths        labels card type data set  \\\n","0            0  train/ace of clubs/001.jpg  ace of clubs       ace    train   \n","1            0  train/ace of clubs/002.jpg  ace of clubs       ace    train   \n","2            0  train/ace of clubs/003.jpg  ace of clubs       ace    train   \n","3            0  train/ace of clubs/004.jpg  ace of clubs       ace    train   \n","4            0  train/ace of clubs/005.jpg  ace of clubs       ace    train   \n","\n","                                               image  \n","0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n","1  [[[246, 248, 248], [249, 251, 251], [247, 249,...  \n","2  [[[0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], ...  \n","3  [[[255, 255, 252], [255, 255, 252], [252, 252,...  \n","4  [[[253, 255, 254], [250, 255, 253], [246, 254,...  "]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["<bound method Series.info of 0       [[[255, 255, 255], [255, 255, 255], [255, 255,...\n","1       [[[246, 248, 248], [249, 251, 251], [247, 249,...\n","2       [[[0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], ...\n","3       [[[255, 255, 252], [255, 255, 252], [252, 252,...\n","4       [[[253, 255, 254], [250, 255, 253], [246, 254,...\n","                              ...                        \n","7620    [[[181, 183, 184], [183, 185, 186], [190, 192,...\n","7621    [[[255, 255, 255], [255, 255, 255], [254, 254,...\n","7622    [[[229, 229, 229], [235, 235, 235], [239, 239,...\n","7623    [[[238, 238, 238], [239, 239, 239], [241, 241,...\n","7624    [[[111, 109, 108], [138, 136, 135], [187, 185,...\n","Name: image, Length: 7625, dtype: object>"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train[\"image\"].info"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: [class index, filepaths, labels, card type, data set, image]\n","Index: []\n"]}],"source":["none_values = data[data['image'].isnull()]\n","print(none_values)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"ename":"IndexError","evalue":"iloc cannot enlarge its target object","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[43], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m     flattened_image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mflatten()  \u001b[38;5;66;03m# Вытягиваем изображение в одномерный массив\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pixel_idx, pixel_value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(flattened_image):\n\u001b[1;32m---> 11\u001b[0m         \u001b[43mnormalized_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m pixel_value \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255.0\u001b[39m  \u001b[38;5;66;03m# Нормализуем значения пикселей\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     normalized_images\u001b[38;5;241m.\u001b[39mloc[idx] \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[idx]\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:908\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    906\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m    907\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_setitem_indexer(key)\n\u001b[1;32m--> 908\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_has_valid_setitem_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m    911\u001b[0m iloc\u001b[38;5;241m.\u001b[39m_setitem_with_indexer(indexer, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexing.py:1646\u001b[0m, in \u001b[0;36m_iLocIndexer._has_valid_setitem_indexer\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_integer(i):\n\u001b[0;32m   1645\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(ax):\n\u001b[1;32m-> 1646\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m   1648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc cannot enlarge its target object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[1;31mIndexError\u001b[0m: iloc cannot enlarge its target object"]}],"source":[]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Все варианты размерностей изображений:\n","(224, 224, 3)\n","()\n"]}],"source":["import numpy as np\n","\n","# Создаем пустой список для хранения всех вариантов размерностей изображений\n","размерности_изображений = []\n","\n","# Проходимся по каждому изображению в датасете и добавляем его размерность в список\n","for image in data['image']:\n","    if isinstance(image, np.ndarray):\n","        размерность = image.shape\n","        if размерность not in размерности_изображений:\n","            размерности_изображений.append(размерность)\n","\n","# Выводим все варианты размерностей изображений\n","print(\"Все варианты размерностей изображений:\")\n","for размерность in размерности_изображений:\n","    print(размерность)"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Количество изображений с пустой размерностью: 1\n"]}],"source":["# Создаем счетчик для подсчета пустых размерностей\n","количество_пустых_изображений = 0\n","\n","# Проходимся по каждому изображению в датасете и проверяем его размерность\n","for image in data['image']:\n","    if isinstance(image, np.ndarray):\n","        if image.ndim == 0:  # Проверяем, имеет ли изображение пустую размерность\n","            количество_пустых_изображений += 1\n","\n","# Выводим количество изображений с пустой размерностью\n","print(\"Количество изображений с пустой размерностью:\", количество_пустых_изображений)"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Новый размер датасета после удаления изображений с пустой размерностью: (8154, 6)\n"]}],"source":["data_V34 = data[data['image'].apply(lambda x: isinstance(x, np.ndarray) and x.ndim != 0)]\n","\n","# Выводим информацию о новом датасете\n","print(\"Новый размер датасета после удаления изображений с пустой размерностью:\", data_V34.shape)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"ename":"MemoryError","evalue":"Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_V34[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdata_V34\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndarray\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4915\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4780\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4781\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4782\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4788\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4791\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4906\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4907\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4909\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4913\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n","File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n","Cell \u001b[1;32mIn[65], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_V34[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data_V34[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255.0\u001b[39;49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;28;01melse\u001b[39;00m x)\n","\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.15 MiB for an array with shape (224, 224, 3) and data type float64"]}],"source":["data_V34['image'] = data_V34['image'].apply(lambda x: x / 255.0 if isinstance(x, np.ndarray) else x)"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class index</th>\n","      <th>filepaths</th>\n","      <th>labels</th>\n","      <th>card type</th>\n","      <th>data set</th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/001.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/002.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[246, 248, 248], [249, 251, 251], [247, 249,...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/003.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/004.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[255, 255, 252], [255, 255, 252], [252, 252,...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/005.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[253, 255, 254], [250, 255, 253], [246, 254,...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class index                   filepaths        labels card type data set  \\\n","0            0  train/ace of clubs/001.jpg  ace of clubs       ace    train   \n","1            0  train/ace of clubs/002.jpg  ace of clubs       ace    train   \n","2            0  train/ace of clubs/003.jpg  ace of clubs       ace    train   \n","3            0  train/ace of clubs/004.jpg  ace of clubs       ace    train   \n","4            0  train/ace of clubs/005.jpg  ace of clubs       ace    train   \n","\n","                                               image  \n","0  [[[255, 255, 255], [255, 255, 255], [255, 255,...  \n","1  [[[246, 248, 248], [249, 251, 251], [247, 249,...  \n","2  [[[0, 0, 0], [1, 1, 1], [1, 1, 1], [0, 0, 0], ...  \n","3  [[[255, 255, 252], [255, 255, 252], [252, 252,...  \n","4  [[[253, 255, 254], [250, 255, 253], [246, 254,...  "]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["data_V34.head()"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>class index</th>\n","      <th>filepaths</th>\n","      <th>labels</th>\n","      <th>card type</th>\n","      <th>data set</th>\n","      <th>image</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/001.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[6.030862941101084e-08, 6.030862941101084e-0...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/002.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[5.8180089549445756e-08, 5.865309840757133e-...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/003.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[0.0, 0.0, 0.0], [2.365044290627876e-10, 2.3...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/004.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[6.030862941101084e-08, 6.030862941101084e-0...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>train/ace of clubs/005.jpg</td>\n","      <td>ace of clubs</td>\n","      <td>ace</td>\n","      <td>train</td>\n","      <td>[[[5.983562055288528e-08, 6.030862941101084e-0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   class index                   filepaths        labels card type data set  \\\n","0            0  train/ace of clubs/001.jpg  ace of clubs       ace    train   \n","1            0  train/ace of clubs/002.jpg  ace of clubs       ace    train   \n","2            0  train/ace of clubs/003.jpg  ace of clubs       ace    train   \n","3            0  train/ace of clubs/004.jpg  ace of clubs       ace    train   \n","4            0  train/ace of clubs/005.jpg  ace of clubs       ace    train   \n","\n","                                               image  \n","0  [[[6.030862941101084e-08, 6.030862941101084e-0...  \n","1  [[[5.8180089549445756e-08, 5.865309840757133e-...  \n","2  [[[0.0, 0.0, 0.0], [2.365044290627876e-10, 2.3...  \n","3  [[[6.030862941101084e-08, 6.030862941101084e-0...  \n","4  [[[5.983562055288528e-08, 6.030862941101084e-0...  "]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"markdown","metadata":{},"source":["нормализовал данные"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# Находим индексы строк, где значение в столбце 'data set' равно 'train'\n","train_indices = np.where(data['data set'] == 'train')[0]\n","\n","# Находим индексы строк, где значение в столбце 'data set' равно 'test'\n","test_indices = np.where(data['data set'] == 'test')[0]\n","\n","# Находим индексы строк, где значение в столбце 'data set' равно 'valid'\n","valid_indices = np.where(data['data set'] == 'valid')[0]\n","\n","# Используем найденные индексы для разделения датасета\n","train = data.iloc[train_indices]\n","test = data.iloc[test_indices]\n","valid = data.iloc[valid_indices]"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['ace' 'eight' 'five' 'four' 'jack' 'xxx' 'king' 'nine' 'queen' 'seven'\n"," 'six' 'ten' 'three' 'two']\n"]}],"source":["уникальные_значения = data[\"card type\"].unique()\n","print(уникальные_значения)"]},{"cell_type":"markdown","metadata":{},"source":["У нас будет 14 классов "]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"ename":"ValueError","evalue":"Failed to convert a NumPy array to a Tensor (Unsupported object type int).","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     14\u001b[0m               loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     15\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Обучение модели\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Оценка модели\u001b[39;00m\n\u001b[0;32m     21\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test)\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:123\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."]}],"source":["import tensorflow as tf\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Создание модели\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Flatten(input_shape=(224,224)),  # Предполагается, что изображения уже нормализованы\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(128, activation='relu'),\n","    tf.keras.layers.Dense(14)  # 14 классов \"card type\"\n","])\n","\n","# Компиляция модели\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","# Обучение модели\n","model.fit(train, epochs=10, validation_data=valid)\n","\n","# Оценка модели\n","test_loss, test_acc = model.evaluate(test)\n","print('Точность на тестовых данных:', test_acc)\n","\n","# Получение прогнозов модели\n","predictions = model.predict(test)\n","predicted_labels = tf.argmax(predictions, axis=1)\n","\n","# Вычисление confusion matrix и classification report\n","true_labels = ...  # Истинные метки из тестовых данных\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","class_report = classification_report(true_labels, predicted_labels)\n","\n","print('Confusion Matrix:\\n', conf_matrix)\n","print('Classification Report:\\n', class_report)"]},{"cell_type":"markdown","metadata":{},"source":["До этого момента у мен был план вручную создать матрицы изобржений а потом их нормализовать,спустя 9 часов попыток оказалось что оперативной памяти у меня не хватает"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 7624 validated image filenames belonging to 14 classes.\n","Found 265 validated image filenames belonging to 14 classes.\n","Found 265 validated image filenames belonging to 14 classes.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:920: UserWarning: Found 1 invalid image filename(s) in x_col=\"filepaths\". These filename(s) will be ignored.\n","  warnings.warn(\n","c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 502ms/step - accuracy: 0.4110 - loss: 1.8897 - val_accuracy: 0.8264 - val_loss: 0.7045\n","Epoch 2/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 540ms/step - accuracy: 0.7400 - loss: 0.8557 - val_accuracy: 0.8453 - val_loss: 0.5660\n","Epoch 3/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 522ms/step - accuracy: 0.8130 - loss: 0.5776 - val_accuracy: 0.8868 - val_loss: 0.3920\n","Epoch 4/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 519ms/step - accuracy: 0.9063 - loss: 0.3122 - val_accuracy: 0.9057 - val_loss: 0.5153\n","Epoch 5/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 473ms/step - accuracy: 0.9484 - loss: 0.1867 - val_accuracy: 0.9094 - val_loss: 0.4133\n","Epoch 6/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 471ms/step - accuracy: 0.9732 - loss: 0.1007 - val_accuracy: 0.9283 - val_loss: 0.3766\n","Epoch 7/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 482ms/step - accuracy: 0.9860 - loss: 0.0623 - val_accuracy: 0.9208 - val_loss: 0.4523\n","Epoch 8/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 472ms/step - accuracy: 0.9860 - loss: 0.0622 - val_accuracy: 0.9132 - val_loss: 0.4395\n","Epoch 9/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 471ms/step - accuracy: 0.9800 - loss: 0.0907 - val_accuracy: 0.9208 - val_loss: 0.8079\n","Epoch 10/10\n","\u001b[1m239/239\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 473ms/step - accuracy: 0.9903 - loss: 0.0363 - val_accuracy: 0.9208 - val_loss: 0.5500\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step - accuracy: 0.8791 - loss: 0.8451\n","Точность на тестовых данных: 0.8830188512802124\n","\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 120ms/step\n"]},{"ename":"NameError","evalue":"name 'confusion_matrix' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m test_generator\u001b[38;5;241m.\u001b[39mlabels\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Вычисление confusion matrix и classification report\u001b[39;00m\n\u001b[1;32m---> 75\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m(true_labels, predicted_labels)\n\u001b[0;32m     76\u001b[0m class_report \u001b[38;5;241m=\u001b[39m classification_report(true_labels, predicted_labels)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, conf_matrix)\n","\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"]}],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","# Создание генераторов данных для тренировочного, тестового и валидационного наборов\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","\n","# Загрузка данных с использованием генераторов\n","train_generator = train_datagen.flow_from_dataframe(\n","    dataframe=train,\n","    x_col='filepaths',  # Путь к изображениям\n","    y_col='card type',  # Метки классов\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='sparse',\n","      workers=2  # Для SparseCategoricalCrossentropy\n",")\n","\n","test_generator = test_datagen.flow_from_dataframe(\n","    dataframe=test,\n","    x_col='filepaths',\n","    y_col='card type',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='sparse',\n","    workers=2\n",")\n","\n","valid_generator = valid_datagen.flow_from_dataframe(\n","    dataframe=valid,\n","    x_col='filepaths',\n","    y_col='card type',\n","    target_size=(224, 224),\n","    batch_size=32,\n","    class_mode='sparse',\n","    workers=2\n",")\n","\n","# Создание и компиляция модели\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n","    tf.keras.layers.MaxPooling2D((2, 2)),\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(512, activation='relu'),\n","    tf.keras.layers.Dense(14 , activation='softmax')  # 14 классов \"card type\"\n","])\n","\n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","# Обучение модели с использованием генераторов данных\n","history = model.fit(train_generator,\n","                    epochs=15,\n","                    validation_data=valid_generator)\n","\n","# Оценка модели\n","test_loss, test_acc = model.evaluate(test_generator)\n","print('Точность на тестовых данных:', test_acc)\n","\n","# Получение прогнозов модели\n","predictions = model.predict(test_generator)\n","predicted_labels = tf.argmax(predictions, axis=1)\n","\n","# Вычисление confusion matrix и classification report\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","class_report = classification_report(true_labels, predicted_labels)\n","\n","print('Confusion Matrix:\\n', conf_matrix)\n","print('Classification Report:\\n', class_report)\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["model.save(\"model_V5.h5\")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix:\n"," [[3 1 2 2 0 1 1 0 0 2 2 4 2 0]\n"," [3 2 0 0 0 2 1 1 3 1 3 3 1 0]\n"," [2 0 3 3 1 2 2 1 1 2 3 0 0 0]\n"," [2 2 2 0 1 2 2 1 2 2 1 2 1 0]\n"," [1 3 3 2 0 1 3 0 1 1 1 2 2 0]\n"," [2 3 0 2 2 0 1 0 2 2 2 2 1 1]\n"," [3 2 1 1 2 2 1 1 2 2 1 1 1 0]\n"," [1 1 2 1 2 2 1 4 1 1 0 0 3 1]\n"," [0 2 1 1 2 2 2 2 2 3 2 1 0 0]\n"," [1 1 1 1 1 5 1 2 1 1 1 2 2 0]\n"," [1 1 3 2 3 0 1 3 2 0 0 1 3 0]\n"," [2 2 0 2 3 1 2 2 2 1 2 1 0 0]\n"," [3 1 0 1 1 2 1 3 2 3 1 2 0 0]\n"," [0 0 0 0 0 1 2 1 0 1 0 0 0 0]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.12      0.15      0.14        20\n","           1       0.10      0.10      0.10        20\n","           2       0.17      0.15      0.16        20\n","           3       0.00      0.00      0.00        20\n","           4       0.00      0.00      0.00        20\n","           5       0.00      0.00      0.00        20\n","           6       0.05      0.05      0.05        20\n","           7       0.19      0.20      0.20        20\n","           8       0.10      0.10      0.10        20\n","           9       0.05      0.05      0.05        20\n","          10       0.00      0.00      0.00        20\n","          11       0.05      0.05      0.05        20\n","          12       0.00      0.00      0.00        20\n","          13       0.00      0.00      0.00         5\n","\n","    accuracy                           0.06       265\n","   macro avg       0.06      0.06      0.06       265\n","weighted avg       0.06      0.06      0.06       265\n","\n","Classification Report:\n"," 5.399161360454642\n"]}],"source":["from sklearn.metrics import confusion_matrix, classification_report\n","from numpy import sqrt, mean\n","\n","# Затем вы можете использовать функцию mean для вычисления среднего значения\n","RMSE = sqrt(mean((true_labels - predicted_labels) ** 2))\n","\n","# Вычисление confusion matrix и classification report\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","class_report = classification_report(true_labels, predicted_labels)\n","\n","\n","print('Confusion Matrix:\\n', conf_matrix)\n","print('Classification Report:\\n', class_report)\n","print('rmse:\\n', RMSE)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Полнота (Recall): 0.4\n","F1-мера (F1-Score): 0.5\n"]}],"source":["# Вычисление матрицы ошибок\n","conf_matrix = confusion_matrix(true_labels, predicted_labels)\n","\n","# Полнота (Recall) вычисляется как TP / (TP + FN)\n","TP = conf_matrix[1, 1]  # Количество истинно положительных предсказаний\n","FN = conf_matrix[1, 0]  # Количество ложно отрицательных предсказаний\n","recall = TP / (TP + FN)\n","\n","# F1-мера (F1-Score) вычисляется как гармоническое среднее между точностью и полнотой\n","precision = TP / (TP + conf_matrix[0, 1])  # Точность (Precision) = TP / (TP + FP)\n","f1_score = 2 * (precision * recall) / (precision + recall)\n","\n","# Вывод результатов\n","print(\"Полнота (Recall):\", recall)\n","print(\"F1-мера (F1-Score):\", f1_score)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":7748738,"sourceId":70887,"sourceType":"competition"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
