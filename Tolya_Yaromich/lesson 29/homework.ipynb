{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании мне захотелось дообучить  модель на своей переписке из телеграма со своими друзьями,в итоге вышел датасет примерно да 10000 фраз совместо меня и друзей.\n",
    "в качестве модкли для обучения я взял gpt2 и попытаюсь ее дообучить на своих фразах чтобы модель попробовала подражать моему стилю общения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras import models\n",
    "from keras import Sequential\n",
    "from keras import layers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import optimizers\n",
    "from keras.metrics import AUC\n",
    "from keras.regularizers import L1\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup \n",
    "import re\n",
    "import torch\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "print('Cuda version: ' + tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_test =\"./dataset_token_labels.csv\"\n",
    "tokenized_datasets = pd.read_csv(file_path_test, encoding='utf-8')\n",
    "tokenized_datasets.drop(columns=['tokenized_reviews', 'tokens'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        name           type         id  \\\n",
      "0       V14D  personal_chat  200693762   \n",
      "1       V14D  personal_chat  200693762   \n",
      "2       V14D  personal_chat  200693762   \n",
      "3       V14D  personal_chat  200693762   \n",
      "4       V14D  personal_chat  200693762   \n",
      "...      ...            ...        ...   \n",
      "91578  V3N1K  personal_chat  360552278   \n",
      "91579  V3N1K  personal_chat  360552278   \n",
      "91580  V3N1K  personal_chat  360552278   \n",
      "91581  V3N1K  personal_chat  360552278   \n",
      "91582  V3N1K  personal_chat  360552278   \n",
      "\n",
      "                                                messages  \n",
      "0      {'id': 498643, 'type': 'service', 'date': '202...  \n",
      "1      {'id': 498644, 'type': 'message', 'date': '202...  \n",
      "2      {'id': 498645, 'type': 'message', 'date': '202...  \n",
      "3      {'id': 498646, 'type': 'service', 'date': '202...  \n",
      "4      {'id': 498647, 'type': 'message', 'date': '202...  \n",
      "...                                                  ...  \n",
      "91578  {'id': 778920, 'type': 'message', 'date': '202...  \n",
      "91579  {'id': 778921, 'type': 'message', 'date': '202...  \n",
      "91580  {'id': 778922, 'type': 'message', 'date': '202...  \n",
      "91581  {'id': 778923, 'type': 'message', 'date': '202...  \n",
      "91582  {'id': 778934, 'type': 'message', 'date': '202...  \n",
      "\n",
      "[91583 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Создайте пустой список для хранения данных из JSON файлов\n",
    "dataframes = []\n",
    "\n",
    "# Переберите каждый JSON файл в вашем каталоге\n",
    "json_files = [file for file in os.listdir('.') if file.endswith('.json')]\n",
    "for file in json_files:\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        # Загрузите данные из JSON файла\n",
    "        data = json.load(f)\n",
    "        # Преобразуйте данные в DataFrame и добавьте их в список\n",
    "        df = pd.DataFrame(data)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Объедините все DataFrame в один\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Теперь у вас есть один Pandas DataFrame, содержащий данные из всех JSON файлов\n",
    "print(final_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_88918_row0_col0, #T_88918_row0_col1, #T_88918_row0_col2, #T_88918_row0_col3, #T_88918_row1_col0, #T_88918_row1_col1, #T_88918_row1_col2, #T_88918_row1_col3, #T_88918_row2_col0, #T_88918_row2_col1, #T_88918_row2_col2, #T_88918_row2_col3, #T_88918_row3_col0, #T_88918_row3_col1, #T_88918_row3_col2, #T_88918_row3_col3, #T_88918_row4_col0, #T_88918_row4_col1, #T_88918_row4_col2, #T_88918_row4_col3 {\n",
       "  width: 300px;\n",
       "  text-align: left;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_88918\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_88918_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_88918_level0_col1\" class=\"col_heading level0 col1\" >type</th>\n",
       "      <th id=\"T_88918_level0_col2\" class=\"col_heading level0 col2\" >id</th>\n",
       "      <th id=\"T_88918_level0_col3\" class=\"col_heading level0 col3\" >messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88918_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_88918_row0_col0\" class=\"data row0 col0\" >V14D</td>\n",
       "      <td id=\"T_88918_row0_col1\" class=\"data row0 col1\" >personal_chat</td>\n",
       "      <td id=\"T_88918_row0_col2\" class=\"data row0 col2\" >200693762</td>\n",
       "      <td id=\"T_88918_row0_col3\" class=\"data row0 col3\" >{'id': 498643, 'type': 'service', 'date': '2020-09-07T19:53:42', 'date_unixtime': '1599497622', 'actor': 'Tos', 'actor_id': 'user368720613', 'action': 'clear_history', 'text': '', 'text_entities': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88918_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_88918_row1_col0\" class=\"data row1 col0\" >V14D</td>\n",
       "      <td id=\"T_88918_row1_col1\" class=\"data row1 col1\" >personal_chat</td>\n",
       "      <td id=\"T_88918_row1_col2\" class=\"data row1 col2\" >200693762</td>\n",
       "      <td id=\"T_88918_row1_col3\" class=\"data row1 col3\" >{'id': 498644, 'type': 'message', 'date': '2020-09-07T19:55:36', 'date_unixtime': '1599497736', 'from': 'Tos', 'from_id': 'user368720613', 'text': 'Мощно', 'text_entities': [{'type': 'plain', 'text': 'Мощно'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88918_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_88918_row2_col0\" class=\"data row2 col0\" >V14D</td>\n",
       "      <td id=\"T_88918_row2_col1\" class=\"data row2 col1\" >personal_chat</td>\n",
       "      <td id=\"T_88918_row2_col2\" class=\"data row2 col2\" >200693762</td>\n",
       "      <td id=\"T_88918_row2_col3\" class=\"data row2 col3\" >{'id': 498645, 'type': 'message', 'date': '2020-09-07T19:57:03', 'date_unixtime': '1599497823', 'from': 'Tos', 'from_id': 'user368720613', 'text': 'Влад?', 'text_entities': [{'type': 'plain', 'text': 'Влад?'}]}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88918_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_88918_row3_col0\" class=\"data row3 col0\" >V14D</td>\n",
       "      <td id=\"T_88918_row3_col1\" class=\"data row3 col1\" >personal_chat</td>\n",
       "      <td id=\"T_88918_row3_col2\" class=\"data row3 col2\" >200693762</td>\n",
       "      <td id=\"T_88918_row3_col3\" class=\"data row3 col3\" >{'id': 498646, 'type': 'service', 'date': '2020-09-07T20:00:44', 'date_unixtime': '1599498044', 'actor': 'Tos', 'actor_id': 'user368720613', 'action': 'phone_call', 'discard_reason': 'busy', 'text': '', 'text_entities': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88918_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_88918_row4_col0\" class=\"data row4 col0\" >V14D</td>\n",
       "      <td id=\"T_88918_row4_col1\" class=\"data row4 col1\" >personal_chat</td>\n",
       "      <td id=\"T_88918_row4_col2\" class=\"data row4 col2\" >200693762</td>\n",
       "      <td id=\"T_88918_row4_col3\" class=\"data row4 col3\" >{'id': 498647, 'type': 'message', 'date': '2020-09-07T20:10:09', 'date_unixtime': '1599498609', 'from': 'V14D', 'from_id': 'user200693762', 'text': 'Что ты хочешь Толя ?', 'text_entities': [{'type': 'plain', 'text': 'Что ты хочешь Толя ?'}]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18584146b90>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Установите максимальное количество выводимых столбцов\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Выведите данные final_df.head() в ширину максимально\n",
    "final_df.head().style.set_properties(**{'width': '300px', 'text-align': 'left'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'messages'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Предположим, что ваш DataFrame называется final_df\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Извлекаем значения \"actor\" и \"text\" из каждого словаря\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      7\u001b[0m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m final_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Удаляем столбец \"messages\", так как он больше не нужен\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'messages'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Предположим, что ваш DataFrame называется final_df\n",
    "\n",
    "# Извлекаем значения \"actor\" и \"text\" из каждого словаря\n",
    "final_df['actor'] = final_df['messages'].apply(lambda x: x.get('from', ''))\n",
    "final_df['text'] = final_df['messages'].apply(lambda x: x.get('text', ''))\n",
    "\n",
    "# Удаляем столбец \"messages\", так как он больше не нужен\n",
    "final_df.drop(columns=['messages'], inplace=True)\n",
    "\n",
    "# Выводим первые 5 строк нового датасета для проверки\n",
    "print(final_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'messages'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfinal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'messages'"
     ]
    }
   ],
   "source": [
    "print(final_df['messages'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>id</th>\n",
       "      <th>actor</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>V14D</td>\n",
       "      <td>personal_chat</td>\n",
       "      <td>200693762</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>V14D</td>\n",
       "      <td>personal_chat</td>\n",
       "      <td>200693762</td>\n",
       "      <td>Tos</td>\n",
       "      <td>Мощно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>V14D</td>\n",
       "      <td>personal_chat</td>\n",
       "      <td>200693762</td>\n",
       "      <td>Tos</td>\n",
       "      <td>Влад?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>V14D</td>\n",
       "      <td>personal_chat</td>\n",
       "      <td>200693762</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V14D</td>\n",
       "      <td>personal_chat</td>\n",
       "      <td>200693762</td>\n",
       "      <td>V14D</td>\n",
       "      <td>Что ты хочешь Толя ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name           type         id actor                  text\n",
       "0  V14D  personal_chat  200693762                            \n",
       "1  V14D  personal_chat  200693762   Tos                 Мощно\n",
       "2  V14D  personal_chat  200693762   Tos                 Влад?\n",
       "3  V14D  personal_chat  200693762                            \n",
       "4  V14D  personal_chat  200693762  V14D  Что ты хочешь Толя ?"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.drop(columns=['name','type','id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tos' '' 'V14D' 'Xolod 2.0' 'IV4N0V']\n"
     ]
    }
   ],
   "source": [
    "actor_values = final_df['actor'].unique()\n",
    "\n",
    "# Выводим уникальные значения\n",
    "print(actor_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfinal_df\u001b[49m\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(final_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('messager.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_test =\"./messager.csv\"\n",
    "df = pd.read_csv(file_path_test, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actor</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tos</td>\n",
       "      <td>Мощно</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tos</td>\n",
       "      <td>Влад?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>V14D</td>\n",
       "      <td>Что ты хочешь Толя ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>V14D</td>\n",
       "      <td>Я не понимаб</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>V14D</td>\n",
       "      <td>ну ок</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actor                  text\n",
       "1   Tos                 Мощно\n",
       "2   Tos                 Влад?\n",
       "4  V14D  Что ты хочешь Толя ?\n",
       "5  V14D          Я не понимаб\n",
       "6  V14D                 ну ок"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df_clean[\"text\"]\n",
    "text.to_csv('messager2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9b8a8aea2547279febbfe7743b9a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc8543dd74647a3a9a06a095cd15579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342655f0670d45db9d7256d4a3270ce9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe79b5117b04028b741560d0c95c9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d45a57815549c2b857916adf31f1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcfb88362f0640bcb45328a5c7a3579b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Загрузка модели casual language modeling\n",
    "model_name = \"GPT2\"\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Загрузка токенизатора для модели\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_clean[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12889e16decc4a55a43d69c992b759df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/551M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d3881c7d1a4c708692af23804f90dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Dmitriy007/rugpt2_gen_news\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Dmitriy007/rugpt2_gen_news\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "снизу код из hugging face по тому как использовать эту модель не дообучая ее ,она генерирует новости на русском языке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\generation\\configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "\n",
    "input_text = 'Ученик старшего класса лицея № 21 Иван Сидоров из города Адлер полетел в космос на планету Марс.'\n",
    "\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "model.to('cuda')\n",
    "inputs.to('cuda')\n",
    "\n",
    "input_ids = inputs[\"input_ids\"]\n",
    "\n",
    "output = model.generate(\n",
    "input_ids,\n",
    "attention_mask=inputs[\"attention_mask\"],\n",
    "pad_token_id=model.config.bos_token_id,\n",
    "max_length=300,\n",
    "num_beams=5,\n",
    "num_return_sequences=1,\n",
    "top_k=50,\n",
    "top_p=0.90,\n",
    "no_repeat_ngram_size=2,\n",
    "temperature=0.7,\n",
    "early_stopping=True\n",
    ")\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, output))\n",
    "print(generated_text[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "c:\\Users\\anon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d54b40eb72497ba374c6e596a68a83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2541 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2541, training_loss=3.435218471750787, metrics={'train_runtime': 992.1285, 'train_samples_per_second': 20.489, 'train_steps_per_second': 2.561, 'train_loss': 3.435218471750787, 'epoch': 3.0})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "\n",
    "# Загрузка предварительно обученного токенизатора и модели\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Dmitriy007/rugpt2_gen_news\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Dmitriy007/rugpt2_gen_news\")\n",
    "\n",
    "# Подготовка данных для дообучения\n",
    "dataset = TextDataset(\n",
    "    tokenizer=tokenizer,\n",
    "    file_path=\"./messager2.csv\",  # Путь к вашему файлу с данными\n",
    "    block_size=128  # Максимальная длина последовательности\n",
    ")\n",
    "\n",
    "# Инициализация data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "\n",
    "# Настройка аргументов обучения\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",  # Папка для сохранения модели\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,  # Количество эпох обучения\n",
    "    per_device_train_batch_size=8,\n",
    "    save_steps=1000,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "# Создание трейнера для обучения модели\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "# Запуск обучения\n",
    "trainer.train()\n",
    "\n",
    "# Сохранение дообученной модели\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./model2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# Загрузка токенизатора и модели\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Dmitriy007/rugpt2_gen_news\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./model2\")\n",
    "\n",
    "# это промпт\n",
    "input_text = \"Это странно\"\n",
    "\n",
    "# Токенизация \n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Передача модели на GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "inputs.to(device)\n",
    "\n",
    "# Генерация текста\n",
    "output = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    max_length=300,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,  # Использовать режим с выборкой\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    num_beams=5,  # Установить количество лучей больше 1\n",
    "    early_stopping=False  # Отключить раннюю остановку\n",
    ")\n",
    "\n",
    "\n",
    "# Декодирование сгенерированного текста\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Это странно\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,это странно\"\\n\"Да,'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну он определнно генерирует нечто похожее,на правду но мне совсем понятно почему в таком количестве"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='Dmitriy007/rugpt2_gen_news', vocab_size=50257, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50257: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model\n",
    "tokenizer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "22f30260a2b4101620faa352ff4158c8c03486483c8393b76c92b58694587b7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
